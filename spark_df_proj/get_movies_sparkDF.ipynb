{
  "metadata": {
    "name": "get_movies_sparkDF",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Zeppelin notebook to get top N most rated movies\n\n## Description\n\nIt\u0027s a zeppelin notebook to determine the top N most rated movies (by average rating) for each specified genre. It allows to set filters for the search: genres, regular expression, years from and to, as well as a number, showing how many movies of each genre to display. At the same time, it sorts movies by genre and average ratings; in case of the same rating then sort by year and title. There is a paragraph to enter arguments for filtering movies. \n\n## Installation\n#### Requirements \nIt requires [Python](https://www.python.org/downloads/)  v3+ to run, Docker and Bash.\nTo install Zeppelin run command:\n```\ndocker run -p 8080:8080 -v /tmp:/tmp --name zeppelin apache/zeppelin:0.9.0\n```\nThen it will start Zeppelin on port 8080."
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# for overwriting \nspark.conf.set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\", \"true\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Download and unpack MovieLens files\n\nOn next paragraph will be downloaded ml-latest-small Dataset from [MovieLens](https://grouplens.org/datasets/movielens/) web site, unpacked movies.csv and ratings.csv into /tmp/Datasets folder."
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh \n\nif [ -e /tmp/Datasets/ml-latest-small/ratings.csv -a -e /tmp/Datasets/ml-latest-small/movies.csv ]; then \n\techo \"Files csv exists.\"\nelif [ -e /tmp/ml-latest-small.zip ]; then \n\tunzip /tmp/ml-latest-small.zip \\ml-latest-small/ratings.csv \\ml-latest-small/movies.csv -d /tmp/Datasets \n\trm /tmp/ml-latest-small.zip\nelse \n\twget -P /tmp https://files.grouplens.org/datasets/movielens/ml-latest-small.zip \n\tunzip /tmp/ml-latest-small.zip \\ml-latest-small/ratings.csv \\ml-latest-small/movies.csv -d /tmp/Datasets \n\trm /tmp/ml-latest-small.zip\nfi "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Put csv files into hdfs\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nhdfs dfs -mkdir -p /tmp/Datasets/ml-latest-small\n\nhdfs dfs -mkdir -p /tmp/Output\n\nhdfs dfs -put -f /tmp/Datasets/ml-latest-small/movies.csv /tmp/Datasets/ml-latest-small/\n\nhdfs dfs -put -f /tmp/Datasets/ml-latest-small/ratings.csv /tmp/Datasets/ml-latest-small/"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Arguments and variables\nIn next paragraph can be setted parameters(arguments) for filtering. It imports necessary libraries."
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import col, split, explode, regexp_extract, avg, round\n\nMOVIES_LOCAL_PATH \u003d \"///tmp/Datasets/ml-latest-small/movies.csv\" \nRATINGS_LOCAL_PATH \u003d \"///tmp/Datasets/ml-latest-small/ratings.csv\" \nMOVIES_HDFS_PATH \u003d \"hdfs:///tmp/Datasets/ml-latest-small/movies.csv\" \nRATINGS_HDFS_PATH \u003d \"hdfs:///tmp/Datasets/ml-latest-small/ratings.csv\" \nOUTPUT_LOCAL_PATH \u003d \"///tmp/Output/\"\nOUTPUT_HDFS_PATH \u003d \"hdfs:///tmp/Output/\"\nREADING_FORMAT \u003d \u0027csv\u0027\nSAVING_FORMAT \u003d \u0027csv\u0027\n\nN \u003d 4\nGENRES \u003d \"Thriller|Crime|War|Fantasy\"\nREGEXP \u003d \"God\"\nYEAR_TO \u003d None\nYEAR_FROM \u003d 1970\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Local mode\n\nCreate DataFrame of movies and ratings from datasets"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## HDFS mode\nCreate DataFrame of movies and ratings from hdfs file"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nstaging_movies_df \u003d spark.read.format(READING_FORMAT)\\\n                              .options(header\u003d\u0027true\u0027,\n                                       delimiter\u003d\u0027,\u0027,\n                                       path\u003dMOVIES_LOCAL_PATH)\\\n                              .load()\n                               \nstaging_ratings_df \u003d spark.read.format(READING_FORMAT)\\\n                               .options(header\u003d\u0027true\u0027,\n                                        delimiter\u003d\u0027,\u0027,\n                                        path\u003dRATINGS_LOCAL_PATH)\\\n                               .load()\\\n                               .select(col(\u0027movieId\u0027).alias(\u0027Id\u0027),\n                                       col(\u0027rating\u0027).cast(\u0027float\u0027))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nstaging_movies_df \u003d spark.read.format(READING_FORMAT)\\\n                              .options(header\u003d\u0027true\u0027,\n                                       delimiter\u003d\u0027,\u0027,\n                                       path\u003dMOVIES_HDFS_PATH)\\\n                              .load()\n                               \nstaging_ratings_df \u003d spark.read.format(READING_FORMAT)\\\n                               .options(header\u003d\u0027true\u0027,\n                                        delimiter\u003d\u0027,\u0027,\n                                        path\u003dRATINGS_HDFS_PATH)\\\n                               .load()\\\n                               .select(col(\u0027movieId\u0027).alias(\u0027Id\u0027),\n                                       col(\u0027rating\u0027).cast(\u0027float\u0027))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Get filtered movies DataFrame\n\nThis paragraph parse lines from DataFrame which contain data from csv and insert it into parsed_movies_df DataFrame, where will be movieId, genre, title and year columns. Also its filters this data, drop bad data."
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nparsed_movies_df \u003d staging_movies_df.select(\u0027movieId\u0027,\n                                            explode(split(\u0027genres\u0027, \"[|]\")).alias(\u0027genre\u0027),\n                                            regexp_extract(\u0027title\u0027,\"(.+)[ ]+[(](\\\\d{4})[)]\", 1).alias(\u0027title\u0027),\n                                            regexp_extract(\u0027title\u0027,\"(.+)[ ]+[(](\\\\d{4})[)]\", 2).alias(\u0027year\u0027)\n                                            )\nif GENRES:\n    arg_genres \u003d GENRES.split(\u0027|\u0027)\nelse:\n    arg_genres \u003d GENRES\n\n#drop bad data\nfiltered_movies_df \u003d parsed_movies_df.na.drop()\n\nif YEAR_FROM:\n    filtered_movies_df \u003d filtered_movies_df.filter(col(\u0027year\u0027).cast(\"int\") \u003e\u003d YEAR_FROM)\n    \nif YEAR_TO:\n    filtered_movies_df \u003d filtered_movies_df.filter(col(\u0027year\u0027).cast(\"int\") \u003c\u003d YEAR_TO)\n\nif REGEXP:\n    filtered_movies_df \u003d filtered_movies_df.filter(col(\u0027title\u0027).rlike(REGEXP))\n    \nif GENRES:\n    filtered_movies_df \u003d filtered_movies_df.filter(col(\u0027genre\u0027).isin(arg_genres))\n    \n#filtered_movies_df.show(20)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Get result DataFrame of movies with retings\n\nThis paragraph create DataFrame which joines two DataFrames (DataFrame of average rating + filtered movies), then it sorts data in necessary order and receive it like result DataFrame with N-counted distinct genres."
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import row_number\n\nnecessary_ratings_df \u003d filtered_movies_df.join(staging_ratings_df, filtered_movies_df.movieId \u003d\u003d staging_ratings_df.Id, \u0027leftouter\u0027)\\\n                                         .groupBy(\u0027Id\u0027)\\\n                                         .agg(round(avg(\u0027rating\u0027), 3).alias(\u0027rating\u0027))\n                                         \nmovies_with_ratings_df \u003d filtered_movies_df.join(necessary_ratings_df, necessary_ratings_df.Id \u003d\u003d filtered_movies_df.movieId)\\\n                                           .select(\u0027genre\u0027,\n                                                   \u0027title\u0027,\n                                                   \u0027year\u0027,\n                                                   \u0027rating\u0027)\nif N: \n    window_spec \u003d Window.partitionBy(\u0027genre\u0027).orderBy( col(\u0027rating\u0027).desc(), \n                                                       col(\u0027year\u0027).desc(),\n                                                      \u0027title\u0027)\n    movies_with_ratings_df \u003d movies_with_ratings_df.withColumn(\u0027row_number\u0027, row_number().over(window_spec))\\\n                                                   .where(col(\u0027row_number\u0027) \u003c\u003d N)\\\n                                                   .drop(\u0027row_number\u0027)\n\nfinal_movies_df \u003d movies_with_ratings_df.orderBy(\u0027genre\u0027,\n                                                 col(\u0027rating\u0027).desc(),\n                                                 col(\u0027year\u0027).desc(),\n                                                 \u0027title\u0027)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Local mode output"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## HDFS mode output"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfinal_movies_df.write.mode(\u0027overwrite\u0027)\\\n                     .format(SAVING_FORMAT)\\\n                     .options(delimiter\u003d\u0027,\u0027)\\\n                     .save(OUTPUT_LOCAL_PATH)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfinal_movies_df.write.mode(\u0027overwrite\u0027)\\\n                     .format(SAVING_FORMAT)\\\n                     .options(delimiter\u003d\u0027,\u0027)\\\n                     .save(OUTPUT_HDFS_PATH)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Showing results"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Local mode cat result"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## HDFS mode cat result"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\necho \u0027genre, title, year, rating\u0027\ncat /tmp/Output/*"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\necho \u0027genre, title, year, rating\u0027\nhdfs dfs -cat /tmp/Output/*"
    }
  ]
}