{
  "metadata": {
    "name": "get_movies",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Zeppelin notebook to get top N most rated movies\n\n## Description\n\nIt\u0027s a zeppelin notebook to determine the top N most rated movies (by average rating) for each specified genre. It allows to set filters for the search: genres, regular expression, years from and to, as well as a number, showing how many movies of each genre to display. At the same time, it sorts movies by genre and average ratings; in case of the same rating then sort by year and title. There is a paragraph to enter arguments for filtering movies. \n\n## Installation\n#### Requirements \nIt requires [Python](https://www.python.org/downloads/)  v3+ to run, Docker and Bash.\nTo install Zeppelin run command:\n```\ndocker run -p 8080:8080 -v /tmp:/tmp --name zeppelin apache/zeppelin:0.9.0\n```\nThen it will start Zeppelin on port 8080."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Download and unpack MovieLens files\n\nOn next paragraph will be downloaded ml-latest-small Dataset from [MovieLens](https://grouplens.org/datasets/movielens/) web site, unpacked movies.csv and ratings.csv into /tmp/Datasets folder."
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh \n\nif [ -e /tmp/Datasets/ml-latest-small/ratings.csv -a -e /tmp/Datasets/ml-latest-small/movies.csv ]; then \n\techo \"Files csv exists.\"\nelif [ -e /tmp/ml-latest-small.zip ]; then \n\tunzip /tmp/ml-latest-small.zip \\ml-latest-small/ratings.csv \\ml-latest-small/movies.csv -d /tmp/Datasets \n\trm /tmp/ml-latest-small.zip\nelse \n\twget -P /tmp https://files.grouplens.org/datasets/movielens/ml-latest-small.zip \n\tunzip /tmp/ml-latest-small.zip \\ml-latest-small/ratings.csv \\ml-latest-small/movies.csv -d /tmp/Datasets \n\trm /tmp/ml-latest-small.zip\nfi "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Put csv files into hdfs"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nhdfs dfs -mkdir -p /tmp/Datasets/ml-latest-small\n\nhdfs dfs -put -f /tmp/Datasets/ml-latest-small/movies.csv /tmp/Datasets/ml-latest-small/\n\nhdfs dfs -put -f /tmp/Datasets/ml-latest-small/ratings.csv /tmp/Datasets/ml-latest-small/\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Enumeration of required arguments\nThis arguments can be changed to get another list of movies."
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nGENRES \u003d [\u0027Thriller\u0027, \u0027Crime\u0027, \u0027War\u0027, \u0027Fantasy\u0027]\nYEAR_FROM \u003d 1970\nYEAR_TO \u003d 2010\nREGEXP \u003d \u0027God\u0027\nN \u003d 5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Local mode\n\nCreate RDD of movies and ratings from datasets"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## HDFS mode\nCreate RDD of movies and ratings from hdfs file"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd_movies \u003d sc.textFile(\"///tmp/Datasets/ml-latest-small/movies.csv\")\nrdd_ratings \u003d sc.textFile(\"///tmp/Datasets/ml-latest-small/ratings.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd_movies \u003d sc.textFile(\"hdfs:///tmp/Datasets/ml-latest-small/movies.csv\")\nrdd_ratings \u003d sc.textFile(\"hdfs:///tmp/Datasets/ml-latest-small/ratings.csv\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Functions for parse movies rows.\n\nget_title_year function return splitted title and year from line.\nget_genres function split line with whole genres by \u0027|\u0027 and return list of genres. \nget_splitted_line split line by \u0027,\u0027 into movie id, title, year, all genres.\nget_movies_id split line for movie id, title, year, all genres and return just movie id. \nget_list_movies - return id, title, year, genres in special form."
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nimport re\n\n\ndef get_title_year(original_title):\n\n    year \u003d None\n\n    for i in range(0, len(original_title)):\n        original_title[i] \u003d original_title[i].replace(\u0027\"\u0027, \u0027\u0027)\\\n                                             .replace(\u0027(\u0027, \u0027\u0027)\\\n                                             .replace(\u0027)\u0027, \u0027\u0027)\\\n                                             .replace(\u0027\\r\\n\u0027, \u0027\u0027)\n        digits \u003d re.findall(r\u0027\\d\\d\\d\\d+\u0027, original_title[i])\n\n        if digits:\n            year \u003d str(digits[-1])\n            original_title[i] \u003d original_title[i].replace(year, \u0027\u0027)\n\n    title \u003d \u0027\u0027.join(original_title[:])\n\n    return title, year\n\n\ndef get_genres(all_genres):\n\n    if all_genres:\n        distinct_genres \u003d all_genres.split(\u0027|\u0027)\n    else:\n        distinct_genres \u003d None\n\n    return distinct_genres\n    \n    \ndef get_movies_id(line):\n\n    movie_id \u003d line[0]\n    title \u003d line[1]\n    year \u003d line[2]\n    all_genres \u003d line[3]\n    \n    return int(movie_id)\n    \n    \ndef get_splitted_line(line):\n    \n    parts \u003d line.split(\u0027,\u0027)\n    all_genres \u003d get_genres(parts[-1])\n    original_title \u003d []\n    \n    for word in parts[:-1]:\n        \n        if word.isdigit():\n            movie_id \u003d word\n            continue\n        original_title.append(word)\n\n    title, year \u003d get_title_year(original_title)\n\n    return [movie_id, title, year, all_genres]\n    \n    \ndef get_list_movies(line):\n\n    movie_id \u003d line[0]\n    title \u003d line[1]\n    year \u003d line[2]\n    all_genres \u003d line[3]\n    \n    return [int(movie_id), [title, year, all_genres]]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### RDD of filtered movies\n\nheader_movies - first line which is heading of csv file.\nrdd_splitted_movies - RDD splitted into id, title, year and list of genres.\nrdd_filtered_movies - RDD of filtered movies which match the arguments."
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nheader_movies \u003d rdd_movies.first()\n\nrdd_splitted_movies \u003d rdd_movies.filter(lambda line: line !\u003d header_movies)\\\n                                .map(get_splitted_line)\n                                \nrdd_filtered_movies \u003d rdd_splitted_movies.filter(\\\n                            lambda row: bool(re.search(REGEXP, row[1])) and (YEAR_FROM \u003c\u003d int(row[2]) \u003c\u003d YEAR_TO) and (set(GENRES) \u0026 set(row[3]) !\u003d set()) ) \n                            # row[1] - title; row[2] - year; row[3] - list of genres\n\nrdd_filtered_movies.collect()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### RDD of filtered movies id\n\nrdd_of_movies_id - return list of filtered movies for further filtering ratings."
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd_of_movies_id \u003d rdd_filtered_movies.map(get_movies_id)\nrdd_of_movies_id.collect()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Functions for getting average ratings\n\nfilter_id - checks if movie id is in the list and return id and rating.\nget_distinct_ratings - split by \u0027,\u0027 line of csv ratings and return just id with its rating.\nget_average_rating - return average rating by divising the summ by the quantity.\nget_movie_id_for_ratings - return movie id for filtering and counting."
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef filter_id(line, list_of_movies_id):\n    \n    user_id, current_movie_id, rating, timestamp \u003d line.split(\u0027,\u0027)\n    \n    for movie_id in list_of_movies_id:\n        \n        if (int(current_movie_id) \u003d\u003d movie_id):\n            return [int(current_movie_id), float(rating)]\n\n\ndef get_distinct_ratings(line):\n    \n    user_id, movie_id, rating, timestamp \u003d line.split(\u0027,\u0027)\n    \n    return [int(movie_id), float(rating)]\n    \n\ndef get_average_rating(line):\n    \n    movie_id \u003d line[0]\n    quantity \u003d line[1][0]\n    summ \u003d line[1][1]\n    \n    return [movie_id, summ / quantity]\n    \n    \ndef get_movie_id_for_ratings(line):\n    \n    movie_id, rating \u003d line\n    \n    return movie_id"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### RDD of filtered ratings\n\nheader_ratings - first line which is heading of csv file.\nlist_of_movies_id - transform RDD into list of movies id.\nfiltered_ratings - RDD of ratings only such movies which in list."
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nheader_ratings \u003d rdd_ratings.first()\n\nlist_of_movies_id \u003d [movie_id for movie_id in rdd_of_movies_id.collect()]\n#print(list_of_movies_id)\n\n\nfiltered_ratings \u003d rdd_ratings.filter(lambda line: line !\u003d header_ratings)\\\n                          .map(lambda line: [filter_id(line, list_of_movies_id)])\\\n                          .filter(lambda line: line[0]!\u003d None)\n                          \nfiltered_ratings.collect()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### RDD of average ratings\n\nrdd_ratings_sum - return RDD of movie_id with its sum of ratings.\nrdd_movies_quantities - return RDD of movie_id with its quantities.\nrdd_average_ratings - joins two RDD into one with average ratings."
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# line[0][0] - movie_id; line[0][1] - rating\n\nrdd_ratings_sum \u003d filtered_ratings.map(lambda line: (line[0][0], line[0][1]))\\\n                                  .reduceByKey(lambda x, y: x + y)\n                                  \nrdd_movies_quantities \u003d filtered_ratings.map(lambda line: (line[0][0], line[0][1]))\\\n                                        .map(get_movie_id_for_ratings).countByValue()\n\n\nlist_of_id_with_quantities \u003d [(k,v) for k,v in rdd_movies_quantities.items()]\nrdd_movies_id_with_quantities \u003d sc.parallelize(list_of_id_with_quantities)\n\n\nrdd_average_ratings \u003d rdd_movies_id_with_quantities.leftOuterJoin(rdd_ratings_sum)\\\n                                                   .map(get_average_rating)\n\nrdd_average_ratings.collect()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### RDD movies with ratings\n\nrdd_movies_with_ratings - return RDD whitch join movies with its ratings."
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd_movies_with_int \u003d rdd_filtered_movies.map(get_list_movies)\n\nrdd_movies_with_ratings \u003d rdd_movies_with_int.leftOuterJoin(rdd_average_ratings)\n\nrdd_movies_with_ratings.collect()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Functions for filtering and sorting results\n\nget_movies_of_certain_genre - check if genre of movies corresponds to genres in arguments.\nget_list_of_movies - return list of genre, title, year, rating.\nsort_rules - filter for sorting in correct order.\nget_form_for_filter - return list of genre, title, year, rating."
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef get_movies_of_certain_genre(line):\n\n    genre, title, year, rating \u003d line\n    \n    if (genre in GENRES):\n        return [genre, title, year, rating]\n        \n\ndef get_list_of_movies(line, genre):\n    \n    title \u003d line[1][0][0]\n    year \u003d line[1][0][1]\n    rating \u003d line[1][1]\n\n    return [genre, title, year, rating]\n    \n    \ndef sort_rules(row):\n    \n    genre, title, year, rating \u003d row\n    year \u003d int(year)\n    \n    return [genre, -rating, -year, title]\n    \n\ndef get_form_for_filter(row):\n    \n    genre, title, year, rating \u003d row\n    \n    return [genre, [[title, year, rating]]]\n    \n    \ndef get_n_movies(line):\n    res_movies \u003d []\n    count \u003d 1\n    \n    genre, movies \u003d line\n    for movie in movies:\n        if count \u003e N:\n            break\n        title, year, rating \u003d movie\n        res_movies.append([genre, title, year, rating])\n        count +\u003d 1\n    return res_movies\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### RDD of sorted movies\n\nrdd_sorted_movies - filtering by genres and then sorting movies."
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# line[1][0][2] - each genre in genres from RDD\n\nrdd_sorted_movies \u003d rdd_movies_with_ratings.flatMap(lambda line: [get_list_of_movies(line, genre) for genre in line[1][0][2]])\\\n                          .map(get_movies_of_certain_genre)\\\n                          .filter(lambda row: row !\u003d None)\\\n                          .sortBy(sort_rules)\\\n                          .map(get_form_for_filter)\\\n                          .reduceByKey(lambda x, y: x + y )\\\n                          .sortByKey()\n\nrdd_sorted_movies.collect()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### RDD of N movies and save it into folder /tmp/output\n\nrdd_of_n_movies - get N movies of each genre."
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd_of_n_movies \u003d rdd_sorted_movies.flatMap(get_n_movies)\n\nrdd_of_n_movies.saveAsTextFile(\"///tmp/output\")\n\nrdd_of_n_movies.collect()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Print results local"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Print result with HDFS"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\ncat /tmp/output/*"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nhdfs dfs -cat /tmp/output/*"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n### Results in table form"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"%table genre\\ttitle\\tyear\\trating\")\n\nfor genre, title, year, rating in rdd_of_n_movies.collect():\n    print(genre,\u0027\\t\u0027,title,\u0027\\t\u0027,year,\u0027\\t\u0027,rating)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}